{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIRmnHxTuR-4",
        "outputId": "f93d4b1b-3296-4c5e-9719-74d15308dce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 11ms/step - loss: 39.6151 - val_loss: 32.4668\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 23.0095 - val_loss: 13.7548\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 7.4434 - val_loss: 3.8753\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 3.4829 - val_loss: 2.7840\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 2.4949 - val_loss: 2.2965\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 2.0075 - val_loss: 1.8968\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.6589 - val_loss: 1.6234\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.4330 - val_loss: 1.4458\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.2999 - val_loss: 1.3440\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.2090 - val_loss: 1.2725\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.1454 - val_loss: 1.1924\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.0897 - val_loss: 1.1429\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.0337 - val_loss: 1.0863\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.9836 - val_loss: 1.0470\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.9355 - val_loss: 0.9982\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.8912 - val_loss: 0.9506\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.8499 - val_loss: 0.9067\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.8057 - val_loss: 0.8673\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7627 - val_loss: 0.8212\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7213 - val_loss: 0.7951\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6813 - val_loss: 0.7435\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6444 - val_loss: 0.7191\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6139 - val_loss: 0.6773\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5724 - val_loss: 0.6401\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5335 - val_loss: 0.5993\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5054 - val_loss: 0.5684\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4748 - val_loss: 0.5337\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4344 - val_loss: 0.4972\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4054 - val_loss: 0.4645\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3771 - val_loss: 0.4432\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3518 - val_loss: 0.4052\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3232 - val_loss: 0.3723\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3011 - val_loss: 0.3659\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2755 - val_loss: 0.3214\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2507 - val_loss: 0.3044\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2326 - val_loss: 0.2722\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2136 - val_loss: 0.2552\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1979 - val_loss: 0.2354\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1786 - val_loss: 0.2257\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1654 - val_loss: 0.2037\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1571 - val_loss: 0.1940\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.1452 - val_loss: 0.1784\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1360 - val_loss: 0.1888\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1299 - val_loss: 0.1609\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1235 - val_loss: 0.1577\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1176 - val_loss: 0.1505\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1117 - val_loss: 0.1424\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1089 - val_loss: 0.1440\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.1051 - val_loss: 0.1401\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1034 - val_loss: 0.1359\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.1009 - val_loss: 0.1293\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.1001 - val_loss: 0.1328\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0971 - val_loss: 0.1261\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0967 - val_loss: 0.1283\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0946 - val_loss: 0.1257\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0925 - val_loss: 0.1297\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0923 - val_loss: 0.1249\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0917 - val_loss: 0.1220\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0901 - val_loss: 0.1235\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0891 - val_loss: 0.1235\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0880 - val_loss: 0.1241\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0880 - val_loss: 0.1227\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0888 - val_loss: 0.1204\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0879 - val_loss: 0.1210\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0852 - val_loss: 0.1258\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0855 - val_loss: 0.1202\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0848 - val_loss: 0.1182\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0869 - val_loss: 0.1241\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0845 - val_loss: 0.1201\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0825 - val_loss: 0.1201\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0825 - val_loss: 0.1248\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.1217\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0830 - val_loss: 0.1240\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0829 - val_loss: 0.1223\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0810 - val_loss: 0.1215\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0809 - val_loss: 0.1189\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0797 - val_loss: 0.1172\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0801 - val_loss: 0.1212\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0804 - val_loss: 0.1209\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0793 - val_loss: 0.1204\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0783 - val_loss: 0.1183\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0786 - val_loss: 0.1201\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0781 - val_loss: 0.1154\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0774 - val_loss: 0.1280\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0781 - val_loss: 0.1201\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0762 - val_loss: 0.1165\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0767 - val_loss: 0.1205\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0754 - val_loss: 0.1209\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0749 - val_loss: 0.1174\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0752 - val_loss: 0.1221\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0740 - val_loss: 0.1205\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0739 - val_loss: 0.1238\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0757 - val_loss: 0.1172\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0758 - val_loss: 0.1224\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0752 - val_loss: 0.1209\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0744 - val_loss: 0.1253\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0725 - val_loss: 0.1203\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0720 - val_loss: 0.1208\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0714 - val_loss: 0.1203\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0704 - val_loss: 0.1203\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ec41eccdf90>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# Hypothetical scoring function - this is an oversimplification\n",
        "# Assuming higher pressure values indicate worse conditions\n",
        "df['Cervical_Condition_Score'] = df['Cervical_Pressure'].apply(lambda x: round(x / 10))\n",
        "df['Thoracic_Condition_Score'] = df['Thoracic_Pressure'].apply(lambda x: round(x / 10))\n",
        "df['Lumbar_Condition_Score'] = df['Lumbar_Pressure'].apply(lambda x: round(x / 10))\n",
        "df['Sacral_Condition_Score'] = df['Sacral_Pressure'].apply(lambda x: round(x / 10))\n",
        "\n",
        "# Save the updated DataFrame with scores\n",
        "updated_scores_file_path = '/mnt/data/updated_data_with_scores.csv'\n",
        "\n",
        "# Preprocess the dataset (assuming preprocessing is already done as per previous steps)\n",
        "# Make sure to standardize your features as neural networks perform better with normalized data\n",
        "scaler = StandardScaler()\n",
        "features = ['Cervical_Pressure', 'Thoracic_Pressure', 'Lumbar_Pressure', 'Sacral_Pressure', 'Age', 'Height', 'Weight', 'Duration_of_Use']  # Add or remove features based on your dataset\n",
        "X = scaler.fit_transform(df[features])\n",
        "y = df[['Cervical_Condition_Score', 'Thoracic_Condition_Score', 'Lumbar_Condition_Score', 'Sacral_Condition_Score']]  # Assuming these are the targets\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the MLP model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_dim=X_train.shape[1]),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(y_train.shape[1], activation='linear')  # 'linear' activation for regression\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')  # Mean Squared Error loss for regression\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HOmng5vC0Ylm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Make predictions with the model\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Identify the worst-affected region by finding the index of the highest score\n",
        "worst_region_indices = np.argmax(predictions, axis=1)  # Indices of the worst conditions\n",
        "\n",
        "# Translate indices to region names\n",
        "regions = ['Cervical', 'Thoracic', 'Lumbar', 'Sacral']\n",
        "\n",
        "# Calculate the mean score for each region across all trials\n",
        "mean_cervical_score = df['Cervical_Condition_Score'].mean()\n",
        "mean_thoracic_score = df['Thoracic_Condition_Score'].mean()\n",
        "mean_lumbar_score = df['Lumbar_Condition_Score'].mean()\n",
        "mean_sacral_score = df['Sacral_Condition_Score'].mean()\n",
        "\n",
        "# Combine the mean scores into a dictionary for easier comparison\n",
        "mean_scores = {\n",
        "    'Cervical': mean_cervical_score,\n",
        "    'Thoracic': mean_thoracic_score,\n",
        "    'Lumbar': mean_lumbar_score,\n",
        "    'Sacral': mean_sacral_score\n",
        "}\n",
        "\n",
        "# Identify the region with the highest mean score - the higher the score\n",
        "worst_region = max(mean_scores, key=mean_scores.get)\n",
        "worst_score = mean_scores[worst_region]\n",
        "\n",
        "print(f\"The worst affected region is {worst_region} with an average score of {worst_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC7GhOpuuZKb",
        "outputId": "bb5a2eb8-7d03-4666-86c8-80a5a43c7a0d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 4ms/step\n",
            "The worst affected region is Sacral with an average score of 7.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Calculate MSE\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'Mean Squared Error: {mse}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJpSK-vuwhhY",
        "outputId": "e4863d71-7dfa-423e-fc36-be85c7802b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.00038569538310386376\n"
          ]
        }
      ]
    }
  ]
}